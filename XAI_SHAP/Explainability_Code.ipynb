{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install shap %pip install xgboost\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path= r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\LLM_X_test_dataset.xlsx\"\n",
    "ground_truth_col = 'Inhospital Mortalit(TRUE)'\n",
    "model_prediction_col_list = ['Mixtral-8x7B-Instruct-v0.1 ', \t'Llama-3-70B',\t'Mistral-7B-Instruct',\t'-Llama-3-8B',\t'gpt-4o-2024-05-13_outcome',\t'gpt-3.5-turbo-0125_outcome',\t'gpt-4-turbo-2024-04-09_outcome',\t'gpt-4-0613_outcome']\n",
    "columns_to_drop= ['patient medical hidtory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Load the dataset\n",
    "excel_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\LLM_X_test_dataset.xlsx\"\n",
    "data = pd.read_excel(excel_path)\n",
    "\n",
    "# Specify the relevant columns\n",
    "ground_truth_col = 'Inhospital Mortalit(TRUE)'\n",
    "model_prediction_col_list = ['Mixtral-8x7B', 'Llama-3-70B', 'Mistral-7B', 'Llama3-8B', 'GPT4o', 'GPT3.5', 'GPT4T', 'GPT4']\n",
    "columns_to_drop = ['patient medical hidtory']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "feature_columns = [col for col in data.columns if col not in model_prediction_col_list + [ground_truth_col]]\n",
    "scaler = StandardScaler()\n",
    "for col in feature_columns:\n",
    "    unique_values = data[col].unique()\n",
    "    if not set(unique_values).issubset({0, 1}):\n",
    "        data[[col]] = scaler.fit_transform(data[[col]])\n",
    "        \n",
    "        \n",
    "all_shap_stats_df = pd.DataFrame()\n",
    "for model_col in model_prediction_col_list:\n",
    "    # Extract model predictions and input features\n",
    "    X = data[feature_columns]\n",
    "    y = data[model_col]\n",
    "\n",
    "    # Train a surrogate model\n",
    "    surrogate_model = XGBClassifier(random_state=42)  # Added random_state for reproducibility\n",
    "    surrogate_model.fit(X, y)\n",
    "\n",
    "\n",
    "    explainer = shap.Explainer(surrogate_model)\n",
    "    shap_values = explainer(X)  # Use .shap_values(X) for tree-based explainers if using older SHAP versions\n",
    "\n",
    "    # Extract feature names and their SHAP values (absolute values)\n",
    "    shap_values_df = pd.DataFrame(shap_values.values, columns=feature_columns).abs()\n",
    "\n",
    "    # Calculate the mean and standard deviation of SHAP values for each feature\n",
    "    shap_values_stats = shap_values_df.describe().loc[['mean', 'std']]\n",
    "    shap_values_stats = shap_values_stats.rename(index={'mean': f'{model_col}__mean', 'std': f'{model_col}__std'})\n",
    "\n",
    "    all_shap_stats_df = pd.concat([all_shap_stats_df, shap_values_stats])\n",
    "    \n",
    "    # Visualize SHAP values\n",
    "    fig_waterfall, ax_waterfall = plt.subplots()\n",
    "    shap.plots.bar(shap_values.abs.mean(0), max_display=10)\n",
    "    fig_waterfall.savefig(f'LLM___{model_col}_global.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_waterfall)  \n",
    "\n",
    "    # Visualize SHAP values\n",
    "    fig_violin, ax_violin = plt.subplots()\n",
    "    shap.plots.violin(shap_values, max_display=10, plot_type='layered_violin', plot_size=(7,7))\n",
    "    fig_violin.savefig(f'LLM___{model_col}_perinput.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_violin)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_SHAP_scores_to_impact_percentage(df):\n",
    "    # Identifying rows ending with '__mean' and '__std'\n",
    "    mean_rows = df.filter(regex='__mean$', axis=0)\n",
    "    std_rows = df.filter(regex='__std$', axis=0)\n",
    "    \n",
    "    # Calculating the average for each column\n",
    "    mean_average = mean_rows.mean(axis=0)\n",
    "    std_average = std_rows.mean(axis=0)\n",
    "    \n",
    "    # Adding the new rows to the dataframe\n",
    "    df.loc['ALL_average_mean'] = mean_average\n",
    "    df.loc['ALL_average_std'] = std_average\n",
    "    \n",
    "    \n",
    "    df = df.T\n",
    "    mean_cols = df.filter(regex='_mean$')\n",
    "    std_cols = df.filter(regex='_std$')    \n",
    "    \n",
    "    # Initialize dictionaries to store transformed means and stds\n",
    "    impact_scores = {}\n",
    "    impact_stds = {}    \n",
    "    for mean_col, std_col in zip(mean_cols, std_cols):\n",
    "        total_impact = df[mean_col].abs().sum()\n",
    "        # Calculate the relative impact scores\n",
    "        impact_scores[mean_col] = (df[mean_col].abs() / total_impact) * 100\n",
    "        \n",
    "        # Calculate the transformed standard deviations for impact scores\n",
    "        \n",
    "        impact_stds[std_col] = df[std_col] * (impact_scores[mean_col] / df[mean_col].abs())\n",
    "    # Add new columns to the dataframe\n",
    "    for col, scores in impact_scores.items():\n",
    "        impact_col_name = col.replace('_mean', '_impact_score')\n",
    "        df[impact_col_name] = scores\n",
    "    \n",
    "    for col, stds in impact_stds.items():\n",
    "        impact_std_name = col.replace('_std', '_impact_score_std')\n",
    "        df[impact_std_name] = stds        \n",
    "        \n",
    "    # Sort columns based on root feature name, ignoring specific suffixes\n",
    "    sorted_columns = sorted(df.columns, key=lambda x: x.split('_')[0] + x.split('_')[-1])\n",
    "    df = df[sorted_columns]        \n",
    "    return df\n",
    "\n",
    "LLM_shap_stat = transform_SHAP_scores_to_impact_percentage(all_shap_stats_df)\n",
    "LLM_shap_stat\n",
    "#CML_shap_stat.to_excel(r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\CML_shap_stat.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df, mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#FF1F5b', ecolor='#FF1F5b')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    \n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=450, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Age' :'Demographic - Age',\n",
    "              'CR' : 'Lab - Cr',\n",
    "              'sodium': 'Lab - Na',\n",
    "              'MCV': 'Lab - MCV',\n",
    "              'Hemoglobin':'Lab - Hb',\n",
    "              'alkaline phosphatase': 'Lab - ALP',\n",
    "              ' Lymphocyte count': 'Lab - Lymphocyte',\n",
    "              ' Neutrophils percentage': 'Lab - Neutrophil',\n",
    "              'diastolic Blood pressure': 'VS - Diastolic BP',\n",
    "              'O2 saturation without supply': 'VS - O2 Saturation',\n",
    "              'PT' : 'Lab - PT',\n",
    "              'potassium' : 'Lab - K',\n",
    "              'ESR' : 'Lab - ESR',\n",
    "              } \n",
    "       \n",
    "plot_top_10_means(LLM_shap_stat, 'ALL_average_impact_score', 'ALL_average_impact_score_std',naming_dict=naming_dic, \n",
    "                  save_plt_name=\"MAIN__LLM_MeanImpact.svg\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df, mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#F2Acca', ecolor='#F2Acca')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    \n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=450, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Age' :'Demographic - Age',\n",
    "              'CR' : 'Lab - Cr',\n",
    "              'sodium': 'Lab - Na',\n",
    "              'MCV': 'Lab - MCV',\n",
    "              'Hemoglobin':'Lab - Hb',\n",
    "              'alkaline phosphatase': 'Lab - ALP',\n",
    "              ' Lymphocyte count': 'Lab - Lymphocyte',\n",
    "              ' Neutrophils percentage': 'Lab - Neutrophil',\n",
    "              'diastolic Blood pressure': 'VS - Diastolic BP',\n",
    "              'O2 saturation without supply': 'VS - O2 Saturation',\n",
    "\n",
    "              } \n",
    "       \n",
    "plot_top_10_means(LLM_shap_stat, 'GPT4__impact_score', 'GPT4__impact_score_std',naming_dict=naming_dic, \n",
    "                  save_plt_name=\"MAIN__LLM_GPT4Impact.svg\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_shap_stat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df, mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#e3a857', ecolor='#e3a857')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    \n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=450, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Age' :'Demographic - Age',\n",
    "              'CR' : 'Lab - Cr',\n",
    "              'sodium': 'Lab - Na',\n",
    "              'MCV': 'Lab - MCV',\n",
    "              'Hemoglobin':'Lab - Hb',\n",
    "              'alkaline phosphatase': 'Lab - ALP',\n",
    "              ' Lymphocyte count': 'Lab - Lymphocyte',\n",
    "              ' Neutrophils percentage': 'Lab - Neutrophil',\n",
    "              'diastolic Blood pressure': 'VS - Diastolic BP',\n",
    "              'O2 saturation without supply': 'VS - O2 Saturation',\n",
    "              'PT':'Lab - PT',\n",
    "              'potassium':'Lab - K',\n",
    "              'PTT' : 'Lab - PTT',\n",
    "              'Temperature' : 'VS - Temp'\n",
    "\n",
    "              } \n",
    "       \n",
    "plot_top_10_means(LLM_shap_stat, 'Mistral-7B__impact_score', 'Mistral-7B__impact_score_std',naming_dict=naming_dic, \n",
    "                  save_plt_name=\"MAIN__LLM_mistralImpact.svg\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "excel_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\CML_X_test_dataset.xlsx\"\n",
    "data = pd.read_excel(excel_path)\n",
    "\n",
    "# Specify the relevant columns\n",
    "ground_truth_col = 'y_true'\n",
    "model_prediction_col_list = ['logistic regression_y_predicted', 'SVM_y_predicted', 'Decision tree_y_predicted', 'knn_y_predicted', 'Random forest_y_predicted', 'XGboost_y_predicted', 'neural net_y_predicted']\n",
    "columns_to_drop = ['logistic regression_y_predicted2',\t'SVM_y_predicted2',\t'Decision tree_y_predicted2',\t'knn_y_predicted2',\t'Random forest_y_predicted2',\t'XGboost_y_predicted2',\t'neural net_y_predicted2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "feature_columns = [col for col in data.columns if col not in model_prediction_col_list + [ground_truth_col]]\n",
    "\n",
    "all_shap_stats_df = pd.DataFrame()\n",
    "for model_col in model_prediction_col_list:\n",
    "    # Extract model predictions and input features\n",
    "    X = data[feature_columns]\n",
    "    y = data[model_col]\n",
    "\n",
    "    # Train a surrogate model\n",
    "    surrogate_model = XGBClassifier(random_state=42)  # Added random_state for reproducibility\n",
    "    surrogate_model.fit(X, y)\n",
    "\n",
    "\n",
    "    explainer = shap.Explainer(surrogate_model)\n",
    "    shap_values = explainer(X)  # Use .shap_values(X) for tree-based explainers if using older SHAP versions\n",
    "\n",
    "    # Extract feature names and their SHAP values (absolute values)\n",
    "    shap_values_df = pd.DataFrame(shap_values.values, columns=feature_columns).abs()\n",
    "\n",
    "    # Calculate the mean and standard deviation of SHAP values for each feature\n",
    "    shap_values_stats = shap_values_df.describe().loc[['mean', 'std']]\n",
    "    shap_values_stats = shap_values_stats.rename(index={'mean': f'{model_col}__mean', 'std': f'{model_col}__std'})\n",
    "\n",
    "    all_shap_stats_df = pd.concat([all_shap_stats_df, shap_values_stats])\n",
    "    \n",
    "    # Visualize SHAP values\n",
    "    fig_waterfall, ax_waterfall = plt.subplots()\n",
    "    shap.plots.bar(shap_values.abs.mean(0), max_display=10)\n",
    "    fig_waterfall.savefig(f'CML___{model_col}_global.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_waterfall)  \n",
    "\n",
    "    # Visualize SHAP values\n",
    "    fig_violin, ax_violin = plt.subplots()\n",
    "    shap.plots.violin(shap_values, max_display=10, plot_type='layered_violin', plot_size=(7,7))\n",
    "    fig_violin.savefig(f'CML___{model_col}_perinput.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_violin)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_SHAP_scores_to_impact_percentage(df):\n",
    "    # Identifying rows ending with '__mean' and '__std'\n",
    "    mean_rows = df.filter(regex='__mean$', axis=0)\n",
    "    std_rows = df.filter(regex='__std$', axis=0)\n",
    "    \n",
    "    # Calculating the average for each column\n",
    "    mean_average = mean_rows.mean(axis=0)\n",
    "    std_average = std_rows.mean(axis=0)\n",
    "    \n",
    "    # Adding the new rows to the dataframe\n",
    "    df.loc['ALL_average_mean'] = mean_average\n",
    "    df.loc['ALL_average_std'] = std_average\n",
    "    \n",
    "    \n",
    "    df = df.T\n",
    "    mean_cols = df.filter(regex='_mean$')\n",
    "    std_cols = df.filter(regex='_std$')    \n",
    "    \n",
    "    # Initialize dictionaries to store transformed means and stds\n",
    "    impact_scores = {}\n",
    "    impact_stds = {}    \n",
    "    for mean_col, std_col in zip(mean_cols, std_cols):\n",
    "        total_impact = df[mean_col].abs().sum()\n",
    "        # Calculate the relative impact scores\n",
    "        impact_scores[mean_col] = (df[mean_col].abs() / total_impact) * 100\n",
    "        \n",
    "        # Calculate the transformed standard deviations for impact scores\n",
    "        \n",
    "        impact_stds[std_col] = df[std_col] * (impact_scores[mean_col] / df[mean_col].abs())\n",
    "    # Add new columns to the dataframe\n",
    "    for col, scores in impact_scores.items():\n",
    "        impact_col_name = col.replace('_mean', '_impact_score')\n",
    "        df[impact_col_name] = scores\n",
    "    \n",
    "    for col, stds in impact_stds.items():\n",
    "        impact_std_name = col.replace('_std', '_impact_score_std')\n",
    "        df[impact_std_name] = stds        \n",
    "        \n",
    "    # Sort columns based on root feature name, ignoring specific suffixes\n",
    "    sorted_columns = sorted(df.columns, key=lambda x: x.split('_')[0] + x.split('_')[-1])\n",
    "    df = df[sorted_columns]        \n",
    "    return df\n",
    "\n",
    "CML_shap_stat = transform_SHAP_scores_to_impact_percentage(all_shap_stats_df)\n",
    "CML_shap_stat\n",
    "#CML_shap_stat.to_excel(r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\CML_shap_stat.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df,  mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#009ADE', ecolor='#009ADE')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    \n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=450, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Demographic_Age': \"Demographic - Age\" , 'VS_O2satwithoutsupp':\"VS - O2 Saturation\", 'Symptom_LOC':\"Symptom - LOC\", 'LAB_LYMPHH_1': \"Lab - Lymphocyte\",'Symptom_Dyspnea': 'Symptom - Dyspnea', 'Symptom_Mylagia': 'Symptom - Dyspnea', 'Demographic_Gender': 'Demographic - Gender', 'LAB_CR_1' : 'Lab - Crr', 'LAB_PLT_1': 'Lab - PLT', 'VS_RR': 'VS - RR'} \n",
    "       \n",
    "#plot_top_10_means(CML_shap_stat, 'ALL_impact_score', 'ALL_impact_score_std',naming_dict=naming_dic, save_plt_name=\"MAIN__CML_MeanImpact.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df, mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#00deb3', ecolor='#00deb3')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Demographic_Age': \"Demographic - Age\" , 'VS_O2satwithoutsupp':\"VS - O2 Saturation\", 'Symptom_LOC':\"Symptom - LOC\", 'LAB_LYMPHH_1': \"Lab - Lymphocyte\",'Symptom_Dyspnea': 'Symptom - Dyspnea', 'Symptom_Mylagia': 'Symptom - Dyspnea', 'Demographic_Gender': 'Demographic - Gender', 'LAB_CR_1' : 'Lab - Crr', 'LAB_PLT_1': 'Lab - PLT', 'VS_RR': 'VS - RR', 'Symptom_Caugh': 'Symptom - Cough', 'LAB_NA_First':' Lab - Na' } \n",
    "       \n",
    "plot_top_10_means(CML_shap_stat, 'XGboost_y_predicted__mean', 'XGboost_y_predicted__std',naming_dict=naming_dic, \n",
    "                  save_plt_name=\"MAIN__CML_XGBoostImpac.svg\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "excel_path = r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\finetuned_X_ex_features.xlsx\"\n",
    "data = pd.read_excel(excel_path)\n",
    "\n",
    "# Specify the relevant columns\n",
    "ground_truth_col = 'y_true'\n",
    "model_prediction_col_list = ['Fine-Tuned Mistral-7B']\n",
    "columns_to_drop = []\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "feature_columns = [col for col in data.columns if col not in model_prediction_col_list + [ground_truth_col]]\n",
    "\n",
    "all_shap_stats_df = pd.DataFrame()\n",
    "for model_col in model_prediction_col_list:\n",
    "    # Extract model predictions and input features\n",
    "    X = data[feature_columns]\n",
    "    y = data[model_col]\n",
    "\n",
    "    # Train a surrogate model\n",
    "    surrogate_model = XGBClassifier(random_state=42)  # Added random_state for reproducibility\n",
    "    surrogate_model.fit(X, y)\n",
    "\n",
    "\n",
    "    explainer = shap.Explainer(surrogate_model)\n",
    "    shap_values = explainer(X)  # Use .shap_values(X) for tree-based explainers if using older SHAP versions\n",
    "\n",
    "    # Extract feature names and their SHAP values (absolute values)\n",
    "    shap_values_df = pd.DataFrame(shap_values.values, columns=feature_columns).abs()\n",
    "\n",
    "    # Calculate the mean and standard deviation of SHAP values for each feature\n",
    "    shap_values_stats = shap_values_df.describe().loc[['mean', 'std']]\n",
    "    shap_values_stats = shap_values_stats.rename(index={'mean': f'{model_col}__mean', 'std': f'{model_col}__std'})\n",
    "\n",
    "    all_shap_stats_df = pd.concat([all_shap_stats_df, shap_values_stats])\n",
    "    \n",
    "    # Visualize SHAP values\n",
    "    fig_waterfall, ax_waterfall = plt.subplots()\n",
    "    shap.plots.bar(shap_values.abs.mean(0), max_display=10)\n",
    "    fig_waterfall.savefig(f'CML___{model_col}_global.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_waterfall)  \n",
    "\n",
    "    # Visualize SHAP values\n",
    "    fig_violin, ax_violin = plt.subplots()\n",
    "    shap.plots.violin(shap_values, max_display=10, plot_type='layered_violin', plot_size=(7,7))\n",
    "    fig_violin.savefig(f'CML___{model_col}_perinput.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_violin)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_SHAP_scores_to_impact_percentage(df):\n",
    "    # Identifying rows ending with '__mean' and '__std'\n",
    "    mean_rows = df.filter(regex='__mean$', axis=0)\n",
    "    std_rows = df.filter(regex='__std$', axis=0)\n",
    "    \n",
    "    # Calculating the average for each column\n",
    "    mean_average = mean_rows.mean(axis=0)\n",
    "    std_average = std_rows.mean(axis=0)\n",
    "    \n",
    "    # Adding the new rows to the dataframe\n",
    "    df.loc['ALL_average_mean'] = mean_average\n",
    "    df.loc['ALL_average_std'] = std_average\n",
    "    \n",
    "    \n",
    "    df = df.T\n",
    "    mean_cols = df.filter(regex='_mean$')\n",
    "    std_cols = df.filter(regex='_std$')    \n",
    "    \n",
    "    # Initialize dictionaries to store transformed means and stds\n",
    "    impact_scores = {}\n",
    "    impact_stds = {}    \n",
    "    for mean_col, std_col in zip(mean_cols, std_cols):\n",
    "        total_impact = df[mean_col].abs().sum()\n",
    "        # Calculate the relative impact scores\n",
    "        impact_scores[mean_col] = (df[mean_col].abs() / total_impact) * 100\n",
    "        \n",
    "        # Calculate the transformed standard deviations for impact scores\n",
    "        \n",
    "        impact_stds[std_col] = df[std_col] * (impact_scores[mean_col] / df[mean_col].abs())\n",
    "    # Add new columns to the dataframe\n",
    "    for col, scores in impact_scores.items():\n",
    "        impact_col_name = col.replace('_mean', '_impact_score')\n",
    "        df[impact_col_name] = scores\n",
    "    \n",
    "    for col, stds in impact_stds.items():\n",
    "        impact_std_name = col.replace('_std', '_impact_score_std')\n",
    "        df[impact_std_name] = stds        \n",
    "        \n",
    "    # Sort columns based on root feature name, ignoring specific suffixes\n",
    "    sorted_columns = sorted(df.columns, key=lambda x: x.split('_')[0] + x.split('_')[-1])\n",
    "    df = df[sorted_columns]        \n",
    "    return df\n",
    "\n",
    "fine_LLM = transform_SHAP_scores_to_impact_percentage(all_shap_stats_df)\n",
    "fine_LLM\n",
    "#CML_shap_stat.to_excel(r\"C:\\Users\\LEGION\\Documents\\GIT\\Tehran_COVID_Cohort\\DO_NOT_PUBLISH\\CML_shap_stat.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_10_means(df, mean_column_name, std_column_name, naming_dict={}, plot_title=None, save_plt_name=None):\n",
    "    # Extract the means and standard deviations\n",
    "    means = df[mean_column_name]\n",
    "    stds = df[std_column_name]\n",
    "    \n",
    "    # Find the top 10 rows with the highest means\n",
    "    top_10_indices = means.nlargest(10).index\n",
    "    top_10_means = means.loc[top_10_indices]\n",
    "    top_10_stds = stds.loc[top_10_indices]\n",
    "    \n",
    "    # If a naming dictionary is provided, rename the indices\n",
    "    top_10_labels = []\n",
    "    for index in top_10_indices:\n",
    "        if index in naming_dict:\n",
    "            top_10_labels.append(naming_dict[index])\n",
    "        else:\n",
    "            print(f\"{index} not in naming_dict\")\n",
    "            top_10_labels.append(index)\n",
    "    \n",
    "    # Convert the standard deviations into a format compatible with the error bar function:\n",
    "    error = [np.zeros(len(top_10_stds)), top_10_stds] \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.barh(top_10_labels, top_10_means, xerr=error, capsize=0, color='#28b925', ecolor='#28b925')\n",
    "    \n",
    "    # Annotate each bar with the mean value\n",
    "    for bar, mean in zip(bars, top_10_means):\n",
    "        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{mean:.2f}%', \n",
    "                va='center', ha='right', color='white', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Mean Impact Score and SD')\n",
    "    if plot_title:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "    if save_plt_name:\n",
    "        plt.savefig(save_plt_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    " \n",
    "naming_dic = {'Age' :'Demographic - Age',\n",
    "              'CR' : 'Lab - Cr',\n",
    "              'sodium': 'Lab - Na',\n",
    "              'MCV': 'Lab - MCV',\n",
    "              'Hemoglobin':'Lab - Hb',\n",
    "              'alkaline phosphatase': 'Lab - ALP',\n",
    "              ' Lymphocyte count': 'Lab - Lymphocyte',\n",
    "              ' Neutrophils percentage': 'Lab - Neutrophil',\n",
    "              'diastolic Blood pressure': 'VS - Diastolic BP',\n",
    "              'O2 saturation without supply': 'VS - O2 Saturation',\n",
    "              'PT':'Lab - PT',\n",
    "              'potassium':'Lab - K',\n",
    "              'PTT' : 'Lab - PTT',\n",
    "              'Temperature' : 'VS - Temp',\n",
    "              'loss of consciousness': 'Symptomp - LOC',\n",
    "              'Systolic Blood pressure': 'VS- Systolic BP',\n",
    "              'pulse rate': 'VS - Pule Rate',\n",
    "              'Dyspnea': 'Symptom - Dyspnea'\n",
    "\n",
    "              } \n",
    "       \n",
    "plot_top_10_means(fine_LLM, 'Fine-Tuned Mistral-7B__impact_score', 'Fine-Tuned Mistral-7B__impact_score_std',naming_dict=naming_dic, \n",
    "                  save_plt_name=\"MAIN__fineLLM_FinemistralImpac.svg\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
